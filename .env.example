# LLM Provider Configuration
# Options: "anthropic" (default) or "litellm"
LLM_PROVIDER=anthropic
MODEL_NAME=claude-3-5-sonnet-20241022

# Provider-specific API keys
ANTHROPIC_API_KEY=your_api_key_here
# OPENAI_API_KEY=sk-...
# GOOGLE_API_KEY=...

# Optional: Custom API endpoint (provider-agnostic)
# For LiteLLM proxy or alternative providers, set your endpoint here
# Works for ALL providers (OpenAI, Anthropic, custom gateways, etc.)
# LLM_BASE_URL=https://your-litellm-proxy.example.com
#
# Examples:
#   - LiteLLM proxy: https://litellm.example.com
#   - OpenRouter: https://openrouter.ai/api/v1
#   - Local LM Studio: http://localhost:1234/v1
#   - Predibase Gateway: https://aigateways.staging.predibase.com/xxx/router
#
# Backward compatibility: ANTHROPIC_BASE_URL still works if LLM_BASE_URL is not set

# LLM Settings
LLM_MAX_RETRIES=3
LLM_TIMEOUT=60

# Scanner Settings
# Maximum file size in bytes (default: 1MB)
MAX_FILE_SIZE=1000000
